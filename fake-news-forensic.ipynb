{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2345298,"sourceType":"datasetVersion","datasetId":1415853}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Fake News Forensic – Detecting & Summarizing Misinformation with GenAI**","metadata":{}},{"cell_type":"markdown","source":"# **1. Introduction**\nIn this project, we address the growing problem of misinformation by leveraging generative AI techniques. Our system retrieves fact-check references from a curated database and uses large language models to generate short, grounded explanations of whether a new claim or headline is likely true or false.\n\nWe demonstrate three generative AI capabilities:\n\n1. Embeddings + Vector Store (to store and retrieve similar fact-check statements)\n\n2. Retrieval Augmented Generation (RAG) (to ground AI outputs with actual fact-check snippets)\n\n3. Few-Shot Prompting (to control output style and ensure consistent structure)","metadata":{}},{"cell_type":"markdown","source":"# **2. Libraries & Setup**","metadata":{}},{"cell_type":"code","source":"!pip install -q sentence-transformers langchain chromadb faiss-gpu","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip freeze | grep widgets\n!pip freeze | grep jupyter\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\n\nimport pandas as pd\nimport numpy as np\nimport torch\n\n# For embeddings (SentenceTransformers)\nfrom sentence_transformers import SentenceTransformer\n\n# For vector database, example: FAISS or Chroma\nimport faiss  # or use Chroma or another\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We import the necessary libraries for data manipulation (pandas), creating embeddings (SentenceTransformers), building a vector index (FAISS), and interacting with a language model (OpenAI).","metadata":{}},{"cell_type":"markdown","source":"**Obtain an API Key**\n\nIf you’re calling OpenAI’s API, you need an API key from [platform.openai.com](http://).\n\nStore it as openai.api_key = \"YOUR_KEY_HERE\" in the Notebook.\n\nAlternatively, set it as an environment variable:","metadata":{}},{"cell_type":"code","source":"# For language model calls (OpenAI, Hugging Face, or local)\n# Example with OpenAI:\n\nimport os\nimport openai\nfrom kaggle_secrets import UserSecretsClient\n\nOPENAI_API_KEY = UserSecretsClient().get_secret(\"OPENAI_API_KEY\")\nopenai.api_key = OPENAI_API_KEY\n\n\n\n# ...any additional imports...\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **3. Data Loading & Preprocessing**","metadata":{}},{"cell_type":"code","source":"# 1) Read the CSVs from the ISOT Fake News Dataset\ndf_fake = pd.read_csv('/kaggle/input/isot-fake-news-dataset/Fake.csv')\ndf_true = pd.read_csv('/kaggle/input/isot-fake-news-dataset/True.csv')\n\n# 2) Assign labels\ndf_fake['label'] = 'false'\ndf_true['label'] = 'true'\n\n# 3) Concatenate into a single DataFrame\ndf = pd.concat([df_fake, df_true], ignore_index=True)\n\n# 4) Display 3 rows from each label to get a quick look\ndf_subset = df.groupby('label').head(3)\ndf_subset\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Here’s a quick look at our dataset, which contains a 'text' or 'title' column for the claim/headline and a 'label' column (e.g., “true,” “false”). We’ve already cleaned and prepared these samples so they’re ready for the embedding step.","metadata":{}},{"cell_type":"markdown","source":"# **4. Building & Populating the Vector Store**\n**4.1 Generating Embeddings**","metadata":{}},{"cell_type":"code","source":"# Choose a sentence-transformers model (lightweight example)\nembedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device='cuda')\n\n# Create a list of texts to embed (e.g., headlines or claims)\ntexts = df['text'].tolist()\nlabels = df['label'].tolist()\n\n# Generate embeddings\nembeddings = embedding_model.encode(texts, show_progress_bar=True)\n\nprint(\"Embeddings shape:\", embeddings.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We used a pre-trained model (all-MiniLM-L6-v2) to convert each text snippet into a 384-dimensional embedding vector.","metadata":{}},{"cell_type":"markdown","source":"**4.2 Creating a FAISS Index**","metadata":{}},{"cell_type":"code","source":"dimension = embeddings.shape[1]\nindex = faiss.IndexFlatL2(dimension)\nindex.add(embeddings)\n\nprint(f\"FAISS index size: {index.ntotal}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We’re using a simple FAISS index for vector similarity search. The data is now stored in a format that allows quick retrieval of top-k similar items.","metadata":{}},{"cell_type":"markdown","source":"# **5. Retrieval Augmented Generation (RAG)**\nGiven a new claim or headline, we will:\n\n1. Convert it to an embedding with the same model.\n\n2. Search in our FAISS index for the most similar text(s).\n\n3. Retrieve relevant fact-check info (label, snippet).\n\n4. Send the combined prompt to a language model (e.g., OpenAI) to generate a short, grounded explanation.","metadata":{}},{"cell_type":"markdown","source":"**5.1 Example: Single Query with RAG**","metadata":{}},{"cell_type":"code","source":"\nimport openai\n\ndef retrieve_similar_texts(query, k=3):\n    \"\"\"\n    Given a query (string), return top k similar text entries\n    from the FAISS index.\n    \"\"\"\n    query_emb = embedding_model.encode([query])\n    distances, indices = index.search(query_emb, k)\n\n    results = []\n    for idx in indices[0]:\n        item_text = df.loc[idx, 'text']\n        item_label = df.loc[idx, 'label']\n        results.append((item_text, item_label))\n    return results\n\ndef generate_explanation(query, retrievals):\n    \"\"\"\n    Use the retrieved text & label to produce a short explanation\n    via ChatCompletion in openai>=1.0.0.\n    \"\"\"\n\n    references_str = \"\\n\".join([f\"Claim: {rt[0]} -- Label: {rt[1]}\" for rt in retrievals])\n\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a fact-checking assistant.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": f\"\"\"\nThe user says: '{query}'\n\nWe found these fact-check references:\n{references_str}\n\nBased on these, is the user's claim likely true or false?\nProvide a concise explanation (2-3 sentences) referencing the evidence above.\n            \"\"\"\n        }\n    ]\n\n    # For openai>=1.0.0, we use the 'chat.completions.create' endpoint\n    response = openai.chat.completions.create(\n        model=\"gpt-3.5-turbo\",  # or gpt-4, etc.\n        messages=messages,\n        max_tokens=150,\n        temperature=0\n    )\n\n    # Access the content by attribute, not by subscripting\n    return response.choices[0].message.content.strip()\n\n# Test call\nquery_test = \"Vaccines cause autism.\"\nretrieved = retrieve_similar_texts(query_test, k=3)\nllm_explanation = generate_explanation(query_test, retrieved)\n\nprint(\"----Retrieved Fact Checks----\")\nfor i, (txt, lbl) in enumerate(retrieved):\n    print(f\"{i+1}) [Label: {lbl}] {txt[:80]}...\")\n\nprint(\"\\n----LLM Explanation----\")\nprint(llm_explanation)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Observe how we incorporate both the user’s query and the top matching fact-check references into a single prompt. This ensures our LLM’s response is grounded in real data, reducing hallucinations.","metadata":{}},{"cell_type":"markdown","source":"# **6. Demonstration of Additional Capabilities**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Few-Shot Prompting Example**\n\nWe might want the explanation in a more structured JSON format or a “bullet-point” style. Let’s do a few-shot approach to ensure consistent formatting.","metadata":{}},{"cell_type":"code","source":"import openai\n\ndemo_prompt = \"\"\"\nBelow are examples of how to respond to fact-check queries in JSON:\n\nExample 1:\n{\n  \"label\": \"false\",\n  \"explanation\": \"This claim is contradicted by evidence in X and Y...\"\n}\n\nNow, follow that format exactly:\n\nUser Claim: \"5G towers spread COVID-19.\"\nEvidence: \"Claim: 5G networks cause coronavirus. Label: false\"\n\n{\n   \"label\": \n   \"explanation\":\n}\n\"\"\"\n\n# In openai>=1.0.0, you call openai.chat.completions.create(...)\nresponse_json = openai.chat.completions.create(\n    model=\"gpt-3.5-turbo\", \n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful assistant that outputs JSON.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": demo_prompt\n        }\n    ],\n    max_tokens=100,\n    temperature=0\n)\n\n# Access the content via object attributes, not dict keys\nprint(response_json.choices[0].message.content)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Here, we gave a small “few-shot” style prompt (one or two examples) so the model consistently responds in JSON format, fulfilling the Structured Output capability.","metadata":{}},{"cell_type":"markdown","source":"# **7. Results & Discussion**\n**Observations:**\n\n1. The system effectively retrieves relevant fact-checks for common misinformation claims.\n\n2. LLM explanations are grounded in the references we supply.\n\n**Limitations:**\n\n* If the claim is novel or not in our database, the system might produce uncertain or less accurate results.\n\n* We rely on the original data’s correctness; if the fact-check source is biased or incomplete, our output inherits that limitation.","metadata":{}},{"cell_type":"markdown","source":"# **8. Conclusion & Future Work**\nWe demonstrated a pipeline that harnesses embeddings, vector stores, and retrieval augmented generation to tackle misinformation. By bridging knowledge from a fact-check database with an LLM’s language capabilities, we can produce concise, evidence-based judgments. In future iterations, we might:\n\n* Expand to multilingual content.\n\n* Integrate real-time social media feeds.\n\n* Deploy as a web app or browser extension for on-the-fly checks.","metadata":{}},{"cell_type":"markdown","source":"# **Appendix: References & Acknowledgments**\n\n1. Snopes – Fact-check references\n2. PolitiFact\n3. SentenceTransformers docs\n4. FAISS docs","metadata":{}}]}